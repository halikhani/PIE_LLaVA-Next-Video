{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pie_data import PIE\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Generating trajectory sequence data\n",
      "fstride: 1\n",
      "sample_type: all\n",
      "height_rng: [0, inf]\n",
      "squarify_ratio: 0\n",
      "data_split_type: default\n",
      "seq_type: intention\n",
      "min_track_size: 15\n",
      "random_params: {'ratios': None, 'val_data': True, 'regen_data': False}\n",
      "kfold_params: {'num_folds': 5, 'fold': 1}\n",
      "---------------------------------------------------------\n",
      "Generating database for pie\n",
      "pie annotations loaded from /mnt/esperanto/et/intern/hamidreza/PIE/data_cache/pie_database.pkl\n",
      "---------------------------------------------------------\n",
      "Generating intention data\n",
      "Subset: train\n",
      "Number of pedestrians: 880 \n",
      "Total number of samples: 878 \n",
      "---------------------------------------------------------\n",
      "Generating trajectory sequence data\n",
      "fstride: 1\n",
      "sample_type: all\n",
      "height_rng: [0, inf]\n",
      "squarify_ratio: 0\n",
      "data_split_type: default\n",
      "seq_type: intention\n",
      "min_track_size: 15\n",
      "random_params: {'ratios': None, 'val_data': True, 'regen_data': False}\n",
      "kfold_params: {'num_folds': 5, 'fold': 1}\n",
      "---------------------------------------------------------\n",
      "Generating database for pie\n",
      "pie annotations loaded from /mnt/esperanto/et/intern/hamidreza/PIE/data_cache/pie_database.pkl\n",
      "---------------------------------------------------------\n",
      "Generating intention data\n",
      "Subset: val\n",
      "Number of pedestrians: 243 \n",
      "Total number of samples: 243 \n",
      "---------------------------------------------------------\n",
      "Generating trajectory sequence data\n",
      "fstride: 1\n",
      "sample_type: all\n",
      "height_rng: [0, inf]\n",
      "squarify_ratio: 0\n",
      "data_split_type: default\n",
      "seq_type: intention\n",
      "min_track_size: 15\n",
      "random_params: {'ratios': None, 'val_data': True, 'regen_data': False}\n",
      "kfold_params: {'num_folds': 5, 'fold': 1}\n",
      "---------------------------------------------------------\n",
      "Generating database for pie\n",
      "pie annotations loaded from /mnt/esperanto/et/intern/hamidreza/PIE/data_cache/pie_database.pkl\n",
      "---------------------------------------------------------\n",
      "Generating intention data\n",
      "Subset: test\n",
      "Number of pedestrians: 719 \n",
      "Total number of samples: 714 \n"
     ]
    }
   ],
   "source": [
    "pie_path = './'\n",
    "pie = PIE(data_path=pie_path)\n",
    "traj_sec_train = pie.generate_data_trajectory_sequence(\"train\")\n",
    "traj_sec_val = pie.generate_data_trajectory_sequence(\"val\")\n",
    "traj_sec_test = pie.generate_data_trajectory_sequence(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Horizontal flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageDraw\n",
    "def save_npy_clips(traj_sec_dict, save_dir, down_samp_size):\n",
    "    \n",
    "    # keys are: dict_keys(['image', 'bbox', 'occlusion', 'intention_prob', 'intention_binary', 'ped_id'])\n",
    "    images = traj_sec_dict['image']\n",
    "    pedestrians = traj_sec_dict['ped_id']\n",
    "    bbox_all = traj_sec_dict['bbox']\n",
    "    for i in tqdm(range(len(images))):\n",
    "        cur_image_file_list = images[i]\n",
    "        cur_ped_id = pedestrians[i][0][0]\n",
    "        \n",
    "        # adding the bbox in the frame instead of text prompt\n",
    "        cur_bbox_list = bbox_all[i]\n",
    "        # break\n",
    "        # print(cur_ped_id)\n",
    "        clip = []\n",
    "        # print(cur_image_file_list)\n",
    "        for j, f in enumerate(cur_image_file_list):\n",
    "            cur_bbox = cur_bbox_list[j]\n",
    "            image = Image.open(f)\n",
    "            draw = ImageDraw.Draw(image)\n",
    "            draw.rectangle(cur_bbox, outline='red', width=3)\n",
    "            \n",
    "            # flip images horizontally\n",
    "            flipped_horizontally = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "            clip.append(flipped_horizontally)\n",
    "        \n",
    "        # down-sampling \n",
    "        total_frames = len(clip)\n",
    "        indices = np.arange(0, total_frames, total_frames / down_samp_size).astype(int)\n",
    "        clip = np.array(clip)\n",
    "        clip = clip[indices]\n",
    "\n",
    "        # saving the np array with ped_id as file name\n",
    "        file_name = cur_ped_id\n",
    "        np.save(save_dir + file_name, clip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 243/243 [16:41<00:00,  4.12s/it]\n"
     ]
    }
   ],
   "source": [
    "# save_npy_clips(traj_sec_train, './hamidreza_files/dataset_new_16frames/train_clips/', 16)\n",
    "# save_npy_clips(traj_sec_test, './hamidreza_files/dataset_new_16frames/test_clips/', 16)\n",
    "# save_npy_clips(traj_sec_val, './hamidreza_files/dataset_new_16frames/h_flip/val_clips/', 16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llava-next",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
